{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1accfc3",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813fdd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers, metrics\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a634c146",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Extracting the embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88da424",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The following code works for both menswear & womensear data/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfdc423",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Loading the data\n",
    "path = \"...\"\n",
    "cdf_name = \"name.csv\"\n",
    "cidf_name = 'name.npy'\n",
    "cdf = pd.read_csv(path + mtdf_name)\n",
    "idf = np.load(path + midf_name)\n",
    "print(cdf.shape)\n",
    "print(idf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01794898",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Loading the resnet model\n",
    "resnet_path = \"...\"\n",
    "resnet_name = \"name\"\n",
    "resnet = models.load_model(mresnet_path + mresnet_name)\n",
    "resnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51466c7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Loading the custom model\n",
    "custom_path = \"...\"\n",
    "custom_name = \"name\"\n",
    "custom = models.load_model(mcustom_path + mcustom_name)\n",
    "custom.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e399c7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Resnet embeddings\n",
    "resnetFC = Model(inputs=resnet.input,\n",
    "                  outputs=resnet.get_layer('avg_pool').output)\n",
    "resnet_embeds = resnetFC.predict(idf)\n",
    "resnet_embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83af0368",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Custom embeddings\n",
    "customFC = Model(inputs=custom.input,\n",
    "                  outputs=custom.get_layer('flatten').output)\n",
    "custom_embeds = customFC.predict(idf)\n",
    "custom_embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0652be65",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Saving\n",
    "path = \"...\"\n",
    "ts = datetime.datetime.now()\n",
    "strs = str(ts)[:10] + \"_\" + str(ts)[11:16]\n",
    "strs = strs.replace(\":\", \"-\")\n",
    "\n",
    "name = \"Embeddings_\"\n",
    "\n",
    "resname = name + \"resnet_\" + strs + \".npy\"\n",
    "cusname = name + \"custom_\" + strs + \".npy\"\n",
    "\n",
    "res_path = path + resname\n",
    "cus_path = path + cusname\n",
    "\n",
    "np.save(res_path, resnet_embeds)\n",
    "print(f\"Saved {resname} with shape {resnet_embeds.shape} !\")\n",
    "np.save(cus_path, custom_embeds)\n",
    "print(f\"Saved {cusname} with shape {custom_embeds.shape} !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a9dd5b",
   "metadata": {},
   "source": [
    "# Preparing the data to be filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55395ba1",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Preparing the data to filter by category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20a3119",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The data does not have a variable with the category (tops, dresses, pants...) of each item. <br>\n",
    "Given the wide range of vocabulary and the *variation* in the spelling (e.g. 'polo shirt', 'polo-shirt', 'polo-shirts'...) used to describe the items in their title, grouping them by the keyword in their title was impossible. <br>\n",
    "Thus, I decided to train a computer vision model to classify them in 8 categories (tops, shirts, pants, dress, sweaters, underwear, coats & overall)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f18f92a",
   "metadata": {
    "hidden": true
   },
   "source": [
    "First, we prepare our training data by grouping items with an easily identified keyword in their title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f91d94f",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17792105",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dico_categories = {\n",
    "    #Tops\n",
    "    'polo-shirt': 'tops',\n",
    "    'polo shirt': 'tops',\n",
    "    'tops': 'tops',\n",
    "    'top': 'tops',\n",
    "    'crop top': 'tops',\n",
    "    'crop-top': 'tops',\n",
    "    'croptop': 'tops',\n",
    "    't shirt': 'tops',\n",
    "    't-shirt': 'tops',\n",
    "    'tees': 'tops',\n",
    "    'rugby-shirt': 'tops',\n",
    "    'rugby shirt': 'tops',\n",
    "    'henley': 'tops',\n",
    "    'tee': 'tops',\n",
    "    'tees': 'tops',\n",
    "    'long sleeve': 'tops',\n",
    "    'long-sleeve': 'tops',\n",
    "    't-shirts': 'tops',\n",
    "    't shirts': 'tops',\n",
    "    'polo': 'tops',\n",
    "    'polos': 'tops',\n",
    "    'corset': 'tops',\n",
    "    'tank': 'tops',\n",
    "    't': 'tops',\n",
    "    #Shirts\n",
    "    'shirt': 'shirts',\n",
    "    'cabana': 'shirts',\n",
    "    'shirts': 'shirts',\n",
    "    'overshirt': 'shirts',\n",
    "    'overshirts': 'shirts',\n",
    "    #Pants\n",
    "    'jeans': 'pants',\n",
    "    'chino': 'pants',\n",
    "    'chinos': 'pants',\n",
    "    'trousers': 'pants',\n",
    "    'leggings': 'pants',\n",
    "    'sweatpants': 'pants',\n",
    "    \"sweatpant\": 'pants',\n",
    "    'pants': 'pants',\n",
    "    'sweat pant': 'pants',\n",
    "    'pant': 'pants',\n",
    "    'jean': 'pants',\n",
    "    'shorts': 'pants',\n",
    "    'bermuda': 'pants',\n",
    "    'joggers': 'pants',\n",
    "    'jeggings': 'pants',\n",
    "    'jegging': 'pants',\n",
    "    'leggings': 'pants',\n",
    "    'legging': 'pants',\n",
    "    'short': 'pants',\n",
    "    'trouser': 'pants',\n",
    "    'jogger': 'pants',\n",
    "    'joggers': 'pants',\n",
    "    'flare': 'pants',\n",
    "    'flares': 'pants',\n",
    "    'sweatshort': 'pants',\n",
    "    'sweatshorts': 'pants',\n",
    "    'leg': 'pants',\n",
    "    'legs': 'pants',\n",
    "    'tight': 'pants',\n",
    "    'tights': 'pants',\n",
    "    #Overall _ jumpsuit\n",
    "    'overall': 'overall',\n",
    "    'overalls': 'overall',\n",
    "    'jumpsuit': 'overall',\n",
    "    'jumpsuits': 'overall',\n",
    "    'playsuit': 'overall',\n",
    "    'playsuits': 'overall',\n",
    "    'unitard': 'overall',\n",
    "    'body': 'overall',\n",
    "    'bodysuit': 'overall',\n",
    "    'Jumpsuits/one pieces': 'overall',\n",
    "    # Dresses\n",
    "    'dress': 'dress',\n",
    "    'dresses': 'dress',\n",
    "    'skirt': 'dress',\n",
    "    'skirts': 'dress',\n",
    "    'sarong': 'dress',\n",
    "    'sarongs': 'dress',\n",
    "    'robe': 'dress',\n",
    "    'gown': 'dress',\n",
    "    # sweaters\n",
    "    'sweater': 'sweaters',\n",
    "    'hoodies': 'sweaters',\n",
    "    'jumper': 'sweaters',\n",
    "    'hoodie': 'sweaters',\n",
    "    'cardigan': 'sweaters',\n",
    "    'cardigans': 'sweaters',\n",
    "    'pullover': 'sweaters',\n",
    "    'pullovers': \"sweaters\",\n",
    "    'sweatshirt': 'sweaters',\n",
    "    'sweat-shirt': 'sweaters',\n",
    "    'sweat shirt': 'sweaters',\n",
    "    'hoody': 'sweaters',\n",
    "    'knit': 'sweaters',\n",
    "    'turtleneck': 'sweaters',\n",
    "    'turtlenecks': \"sweaters\",\n",
    "    'pull-over': 'sweaters',\n",
    "    'crewneck': 'sweaters',\n",
    "    'sweatshirts': 'sweaters',\n",
    "    'sweaters': 'sweaters',\n",
    "    'crew': 'sweaters',\n",
    "    'sweat': 'sweaters',\n",
    "    'sweats': 'sweaters',\n",
    "    'fleece': 'sweaters',\n",
    "    'fleeces': 'sweaters',\n",
    "    'hood': 'sweaters',\n",
    "    #Underwear & swim\n",
    "    'socks': 'underwear',\n",
    "    'underwear': 'underwear',\n",
    "    'pyjamas': 'underwear',\n",
    "    'trunks': 'underwear',\n",
    "    'trunk': 'underwear',\n",
    "    'boxer': 'underwear',\n",
    "    'boxers': 'underwear',\n",
    "    'brief': 'underwear',\n",
    "    'briefs': 'underwear',\n",
    "    'bra': 'underwear',\n",
    "    'bralette': 'underwear',\n",
    "    'bathrobe': 'underwear',\n",
    "    'panty': 'underwear',\n",
    "    'panties': 'underwear',\n",
    "    'lingerie': 'underwear',\n",
    "    'tights': 'underwear',\n",
    "    'thong': 'underwear',\n",
    "    'bras': 'underwear',\n",
    "    'bottom': 'underwear',\n",
    "    'bottoms': 'underwear',\n",
    "    'bralet': 'underwear',\n",
    "    'bralets': 'underwear',\n",
    "    'sportsbra': 'underwear',\n",
    "    'sportbra': 'underwear',\n",
    "    'sportbras': 'underwear',\n",
    "    'sportsbras': 'underwear',\n",
    "    'bikini': 'underwear',\n",
    "    'bikinis': 'underwear',\n",
    "    'thongs': 'underwear',\n",
    "    'bikini-top': 'underwear',\n",
    "    'bikini top': 'underwear',\n",
    "    'swimshort': 'underwear',\n",
    "    'swimwear': 'underwear',\n",
    "    'swim-short': 'underwear',\n",
    "    'swimshorts': 'underwear',\n",
    "    'swim-shorts': 'underwear',\n",
    "    'volley-short': 'underwear',\n",
    "    'volley-shorts': 'underwear',\n",
    "    'volley short': 'underwear',\n",
    "    'volley shorts': 'underwear',\n",
    "    'bikini': 'underwear',\n",
    "    'saron': 'underwear',\n",
    "    'swimsuit': 'underwear',\n",
    "    'swim-suit': 'underwear',\n",
    "    'swim suit': 'underwear',\n",
    "    'swimming trunks': 'underwear',\n",
    "    'beachwear': 'underwear',\n",
    "    'swim trunk': 'underwear',\n",
    "    'swim trunks': 'underwear',\n",
    "    'swim-trunks': 'underwear',\n",
    "    'pajamas': 'underwear',\n",
    "    'pajama': 'underwear',\n",
    "    'pyjama': 'underwear',\n",
    "    'bathing': 'underwear',\n",
    "    'swimming': 'underwear',\n",
    "    #Coats & jackets\n",
    "    'vest': 'coats',\n",
    "    'gilet': 'coats',\n",
    "    'coat': 'coats',\n",
    "    'jacket': 'coats',\n",
    "    'puffer': 'coats',\n",
    "    'trench': 'coats',\n",
    "    'blazer': 'coats',\n",
    "    'blazers': 'coats',\n",
    "    'parka': 'coats',\n",
    "    'anorak': 'coats',\n",
    "    'blouse': 'coats',\n",
    "    'bomber': 'coats',\n",
    "    'jersey': \"coats\",\n",
    "    'bombers': 'coats',\n",
    "    'jackets': 'coats',\n",
    "    'coats': 'coats',\n",
    "    'vests': 'coats',\n",
    "    'mac': 'coats',\n",
    "    'poncho': 'coats',\n",
    "    'ponchos': 'coats',\n",
    "    'overcoat': 'coats',\n",
    "    'overcoats': 'coats',\n",
    "    'windbreaker': \"coats\",\n",
    "    \"windbreakers\": 'coats'\n",
    "}\n",
    "\n",
    "second_dic = {\n",
    "    'tops': 0,\n",
    "    'shirts': 1,\n",
    "    'pants': 2,\n",
    "    'dress': 3,\n",
    "    'sweaters': 4,\n",
    "    'underwear': 5,\n",
    "    'coats': 6,\n",
    "    'overall': 7\n",
    "}\n",
    "\n",
    "\n",
    "def classify_by_title(x):\n",
    "    categ = \"\"\n",
    "    x = x.split(\" \")\n",
    "    for word in x:\n",
    "        if word.lower() in dico_categories.keys():\n",
    "            categ = dico_categories[word.lower()]\n",
    "    if categ == \"\":\n",
    "        categ = \"NA\"\n",
    "    return categ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a01658",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#We only need the keywords extracted from the titles\n",
    "X_temporary = cdf['Title'].apply(classify_by_title)\n",
    "#We can exclude the items for which no category could be extracted from their title\n",
    "X = midf[tt[tt != \"NA\"].index]\n",
    "\n",
    "#For our dependent variable, we can One-Hot encode it - each category is attributed a key\n",
    "y = to_categorical(X.apply(lambda x: second_dic[x]))\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2349533a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Preparing train and test sets\n",
    "X_img_train, X_img_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "print(f'X train shape: {X_img_train.shape}')\n",
    "print(f'y train shape: {y_train.shape}')\n",
    "print(f'X test shape: {X_img_test.shape}')\n",
    "print(f'y test shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f0cc89",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's start from a ResNet-50 model which we train to classify items by their category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f57f48f",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Training a ResNet-50 model to categorize items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36b010b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Loading resnet\n",
    "def load_model():\n",
    "    model = ResNet50()\n",
    "    return model\n",
    "\n",
    "\n",
    "#freeze the resnet layers\n",
    "def set_nontrainable_layers(model):\n",
    "    # Set the first layers to be untrainable\n",
    "    model.trainable = False\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_resnet():\n",
    "    res = load_model()\n",
    "    res = set_nontrainable_layers(res)\n",
    "    resFC = res.get_layer('avg_pool').output\n",
    "\n",
    "    output = layers.Flatten(name='new_flatten')(resFC)\n",
    "    #output = layers.Dense(1000, activation='relu', name='dense')(output)\n",
    "    output = layers.Dense(500, activation='relu', name='dense1')(output)\n",
    "    output = layers.Dense(250, activation='relu', name='dense2')(output)\n",
    "    output = layers.Dense(8, activation='softmax', name='prediction')(output)\n",
    "    resnet_model = Model(res.input, output)\n",
    "\n",
    "    return resnet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7715e8a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rmodel = load_resnet()\n",
    "rmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8da7bb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Add parameters to compile the model\n",
    "lr_schedule = ExponentialDecay(initial_learning_rate=0.001,\n",
    "                               decay_steps=5000,\n",
    "                               decay_rate=0.9)\n",
    "adam = Adam(learning_rate=lr_schedule)\n",
    "f1_score = F1Score(num_classes=8)\n",
    "\n",
    "# Compiling model\n",
    "rmodel.compile(optimizer=adam,\n",
    "               loss='categorical_crossentropy',\n",
    "               metrics=['accuracy', 'Precision', f1_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c332dc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Fitting the model\n",
    "es = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "\n",
    "rhistory = rmodel.fit(X_img_train,\n",
    "                      y_train,\n",
    "                      validation_split=0.2,\n",
    "                      epochs=15,\n",
    "                      verbose=1,\n",
    "                      batch_size=32,\n",
    "                      callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53127d91",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rmodel.evaluate(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888de214",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "predictions = rmodel.predict(widf, verbose=1)\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e54068",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_path = \"...\"\n",
    "\n",
    "ts = datetime.datetime.now()\n",
    "strs = str(ts)[:10] + \"_\" + str(ts)[11:16]\n",
    "strs = strs.replace(\":\", \"-\")\n",
    "\n",
    "model_file_name = \"Categorization_\" + strs\n",
    "rmodel.save(model_path + model_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ab01b6",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Assigning categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b3ed51",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Once the model trained, let's use it to assign each item a category.  <br>\n",
    "The model has a 75% accuracy score. As a result, we will only use it to classify items whose category can not be derived from their title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dec0c9c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def categorize(tdf, idf):\n",
    "    #Assigning categories based on the title\n",
    "    tdf[\"Title\"] = tdf['Title'].apply(\n",
    "        lambda x: x.replace(\"Long Sleeve\", \"long-sleeve\"))\n",
    "    cat_named = list(tdf['Title'].apply(classify_by_title))\n",
    "    num_NA = pd.DataFrame(cat_named)[0].value_counts()['NA']\n",
    "    print(f'There are {num_NA} items without a clear category in their title -> need to be predicted ')\n",
    "\n",
    "    #Assuming the model was saved - Importing DL model\n",
    "    print(\"Now importing the DL model to predict clothing categories\")\n",
    "    model_path = \"...\"\n",
    "    catmo_name = \"name\"\n",
    "    catmodel = models.load_model(model_path + catmo_name)\n",
    "    print(\"Model imported, now making predictions\")\n",
    "\n",
    "    #Assignin categories of NA items\n",
    "    preds = catmodel.predict(idf, verbose=1)\n",
    "    cat_preds = []\n",
    "    for i in list(np.argmax(preds, axis=1)):\n",
    "        cat_preds.append(list(second_dic.keys())[i])\n",
    "\n",
    "    cat_fin = []\n",
    "    counter = 0\n",
    "    for i in cat_named:\n",
    "        if i == \"NA\":\n",
    "            valu = cat_preds[counter]\n",
    "        else:\n",
    "            valu = i\n",
    "        counter += 1\n",
    "        cat_fin.append(valu)\n",
    "    print(\"Done with the predictions\")\n",
    "    return pd.DataFrame(cat_fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c5039c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "catdf = categorize(cdf, idf)\n",
    "ctdf['Category'] = catdf[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a2667c",
   "metadata": {},
   "source": [
    "## Preparing the data to filter by budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e9f258",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_price(x):\n",
    "    #Function to drop the $ in front of the price\n",
    "    new_price = []\n",
    "    for i in x:\n",
    "        if i != '$':\n",
    "            new_price.append(i)\n",
    "    new_price = ''.join(new_price)\n",
    "    new_price = new_price.replace(\",\", \"\")\n",
    "    return new_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2734868b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf['New_price'] = cdf['Price'].apply(clean_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2f5595",
   "metadata": {},
   "source": [
    "Once the price cleaned, we will group items by budget. <br>\n",
    "Having browsed several fashion websites, I came up with 4 budget brackets, and their threshold for each category of item. <br>\n",
    "Example: Coats costing less than **£65** are consider **accessible**, those between **£65 and £135** are in the **intermediate** budget, between **£135 and £250** in the **premium** segment, while those worth more than **£250** are deemed **luxury** items. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935f5bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def budget(cat, price):\n",
    "    #Takes as an argument both the price and the category\n",
    "    tops_budget = {20: 1, 35: 2, 60: 3}\n",
    "    shirts_budget = {30: 1, 60: 2, 120: 3}\n",
    "    pants_budget = {40: 1, 70: 2, 140: 3}\n",
    "    dress_budget = {40: 1, 80: 2, 150: 3}\n",
    "    sweaters_budget = {30: 1, 60: 2, 120: 3}\n",
    "    underwear_budget = {10: 1, 25: 2, 40: 3}\n",
    "    coats_budget = {65: 1, 135: 2, 250: 3}\n",
    "    overall_budget = dress_budget\n",
    "\n",
    "    dic_budget = {\n",
    "        'tops': tops_budget,\n",
    "        'shirts': shirts_budget,\n",
    "        'pants': pants_budget,\n",
    "        'dress': dress_budget,\n",
    "        'sweaters': sweaters_budget,\n",
    "        'underwear': underwear_budget,\n",
    "        'coats': coats_budget,\n",
    "        'overall': overall_budget\n",
    "    }\n",
    "\n",
    "    budgets = []\n",
    "\n",
    "    for i in range(len(cat)):\n",
    "        item_cat = cat[i]\n",
    "        item_range = dic_budget[item_cat]\n",
    "        for bracket in item_range.keys():\n",
    "            if float(price[i]) < bracket:\n",
    "                item_budget = item_range[bracket]\n",
    "                break\n",
    "            else:\n",
    "                item_budget = 4\n",
    "        budgets.append(item_budget)\n",
    "\n",
    "    return budgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796da764",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf['Budget'] = budget(list(cdf['Category']), list(cdf['New_price']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf70df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(cdf['Budget']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6416b846",
   "metadata": {},
   "source": [
    "## Preparing the data to filter by size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0866100c",
   "metadata": {},
   "source": [
    "Preparing the data to be filter by size - i.e. grouping it by a common size scale - also proved to be complicated given the wide variety of sizes used by brands and the different websites the data was scrapped from. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d506c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_size = {\n",
    "        'XXS': 'XX-Small',\n",
    "        'XS': '1X-Small',\n",
    "        'S': '0X-Small',\n",
    "        'M': 'Medium',\n",
    "        'L': '0X-Large',\n",
    "        'XL': '1X-Large',\n",
    "        'XXL': '2X-Large',\n",
    "        '3XL': '3X-Large',\n",
    "        'XXXL': '3X-Large',\n",
    "        '(XS)': '1X-Small',\n",
    "        '(S)': '0X-Small',\n",
    "        '(M)': 'Medium',\n",
    "        '(L)': '0X-Large',\n",
    "        '(XL)': '1X-Large',\n",
    "        '(XXL)': '2X-Large',\n",
    "        '(3XL)': '3X-Large',\n",
    "        '(XXXL)': '3X-Large',\n",
    "        'One Size': 'One Size',\n",
    "        '(XXS)': '2X-Small',\n",
    "        'X-Small': '1X-Small',\n",
    "        'XX-Small': '2X-Small',\n",
    "        'XXX-Small': '3X-Small',\n",
    "        'Small': '0X-Small',\n",
    "        'Medium': 'Medium',\n",
    "        'Large': '0X-Large',\n",
    "        'X-Large': '1X-Large',\n",
    "        'XX-Large': \"2X-Large\",\n",
    "        '3X-Large': '3X-Large',\n",
    "        'XXX-Large': \"3X-Large\"}\n",
    "\n",
    "\n",
    "def top_size(x):\n",
    "    #Function to clean the size of tops (shits, tshirts, sweaters...)\n",
    "    new_x = []\n",
    "\n",
    "    x = x.split(\" \")\n",
    "    for sz in x:\n",
    "        if sz in dico_size.keys():\n",
    "            new_x.append(dico_size[sz])\n",
    "\n",
    "    new_x = \" | \".join(new_x)\n",
    "\n",
    "    if new_x == \"\":\n",
    "        new_x = x\n",
    "        new_x = \" \".join(new_x)\n",
    "    print(new_x)\n",
    "    if new_x == ['One', 'Size']:\n",
    "        new_x = ['One Size']\n",
    "    return new_x\n",
    "\n",
    "def pant_size(cat, size):\n",
    "    #This function allows to handle the size of pants\n",
    "    #Top sizes function only handle X L M S format but not waist / inseam format for pants, as this function does\n",
    "    #This function takes into argument the list of categories and list of 'clean sizes'\n",
    "    #That is sizes already cleanned by the top_sizes function because some pants are in the S M L XL format\n",
    "    new_size = []\n",
    "    for i in range(len(cat)):\n",
    "        if cat[i] == 'pants':\n",
    "            split = size[i].split(\" | \")\n",
    "            if split[0] in dico_size.values():\n",
    "                #Situation where size -> M L XL format\n",
    "                new_size.append(size[i])\n",
    "                continue\n",
    "            else:\n",
    "                #Situation where size -> 32\" or 32\" x 32\" format\n",
    "                int_size = []\n",
    "                for i in split:\n",
    "                    int_size.append(i[:3])\n",
    "                new_size.append(\" | \".join(int_size))\n",
    "        else:\n",
    "            new_size.append(size[i])\n",
    "            \n",
    "    return new_size\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec55e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = mtdf['Sizing'].apply(top_size)\n",
    "mtdf['Clean_sizes'] = size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a70957",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_and_pant_sizes = pant_size(list(mtdf['Category']), list(mtdf['Clean_sizes']))\n",
    "cdf['Clean_sizes'] = top_and_pant_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a76fea",
   "metadata": {},
   "source": [
    "## Saving the modified DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dff89db",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"...\"\n",
    "ts = datetime.datetime.now()\n",
    "strs = str(ts)[:10] + \"_\" + str(ts)[11:16]\n",
    "strs = strs.replace(\":\",\"-\")\n",
    "\n",
    "name = \"Clean_DataFrame_\"\n",
    "\n",
    "file_name = name + strs + \".csv\"\n",
    "print(f\"Saved {file_name} !\")\n",
    "cdf.to_csv(path + file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "267px",
    "width": "260px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
